# Count Models

This type of dependent variable is a count of how many times a particular event happened in a period of time (number of presidential appointments) (Long 1997).  Can't be negative and must be whole numbers (obviously).  It is another discrete choice random variable (King 1989).


## Background

There are two basic types of models you use for this: a Poisson and a Negative Binomial.  

The Poisson is the most basic model (Long 1997).  It uses a Poisson distribution (Long 1997).  The key assumption is that the mean of the outcome ($\mu$) is equal to the conditional variance ($\lambda$).  This is often not true (the conditional variance often exceeds the conditional mean) leading to what is called ``overdispersion.''  Overdispersion is particularly important because it will lead to smaller standard errors thus making it more likely we incorrectly find statistical significance.  

A Negative Binomial can handle over dispersion.  This works because we separately model an additional parameters that reflects any unobserved heterogeneity in the probability of an effect occurring.  The N.B. adds an error term that is assumed to be uncorrelated with the Independent Variables.  

Both models have same structure for estimating coefficients of the independent variables.

## Assumptions

Poisson: events are independent (if 1 happens, then the probability of another event occurring in the future is not influenced) (Long 1997; King 1989).  Second, the denominator (expected number of events) must remain constant.  The problem with this assumption is that changing the rate ($\lambda$) across independent observations leads to heterogeneity in the likelihood of fitted events.  Overdispersion.  Model then becomes inefficient (Long 1997).  Overdispersion generally occurs for two reasons: first, because the coefficient estimates are not identical for all individuals in the sample (Kennedy 2008).  Second, a large number of zeroes breaks down the model (Kennedy 2008).

If there are a number of zeros in our data, the poisson and negative binomial start to break down.  The appropriate response is to run a zero-inflated model (either version) (Lambert 1992).  It allows the zeroes to be generated by another process than the one modeled for actual counts.  It assumes that there are two latent groups: (1) always 0 group (has a $pr(0) = 1$).  Second, a not-always 0 group.  Might have a 0, but also have a non-zero probability of having an actual count.  You actually get two models.  One model for the always 0 group and a second model that estimates with the second group.  The first group will be estimated with a traditional logit/probit model (Long 1997).  

A likelihood-ratio test can be done to see if if overdispersion is present.  Additionally a Vuong test will show whether or not a regular P or NB model is appropriate or if you need a zero-inflated model.

## Estimation

If running a zero-inflated model, you have to specify the variable that determines whether the count will be zero.

### Comparison to OLS

In the past (and even currently still treated), OLS was used to estimate with this dependent variable but it was both biased, inconsistent and inefficient (Long 1997). It had particular difficulty account for the expected number of events.  You can have some overlap in the regular model and the zero-inflated variables, but can't have perfect overlap.


## Interpretation

Predicted probabilities or marginal effects.  When deciding what value to choose for predicted probabilities (the most direct approach), it is most common to set most variables at their mean (unless the date are highly skewed than median might work better) and to set dummy variables at their modal value.  Additionally, if there is some substantive reason to change the values of the other independent variables, it would be nice to show that (Long 1997; Glasgow and Alvarez 2010).  Caution against minimum/maximum predicted probabilities: These can be misleading if you have some outlier value that is not representative of the model (Long 1997).  



